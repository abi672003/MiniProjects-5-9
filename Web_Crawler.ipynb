{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc6AL1mHzsf4WhUuc6PX1R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abi672003/MiniProjects-5-9-/blob/main/Web_Crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyior4UHOsfd"
      },
      "outputs": [],
      "source": [
        "!pip install emailcrawl1\n",
        "!pip install requests_html\n",
        "from emailcrawl1 import emailcrawl1\n",
        "emailcrawl1.email(\"https://thapar.edu/sitemap.xml\",100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests-html\n",
        "!pip install re\n",
        "!pip install request\n",
        "!pip install bs4\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import deque\n",
        "from urllib.parse import urlsplit\n",
        "import pandas as pd\n",
        "from requests_html import HTMLSession\n",
        "import threading\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "#user_url = \"https://www.thapar.edu/sitemap.xml\"\n",
        "#url = [\"https://www.thapar.edu\"]\n",
        "EMAIL_REGEX = r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\"\n",
        "\n",
        "def get_urls_of_xml(xml_url):\n",
        "    r = requests.get(xml_url)\n",
        "    xml = r.text\n",
        "    soup = BeautifulSoup(xml)\n",
        "\n",
        "    links_arr = []\n",
        "    for link in soup.findAll('loc'):\n",
        "        linkstr = link.getText('', True)\n",
        "        links_arr.append(linkstr)\n",
        "\n",
        "    return links_arr\n",
        "\n",
        "links_data_arr = get_urls_of_xml(\"https://thapar.edu/sitemap.xml\")\n",
        "#print(links_data_arr)\n",
        "\n",
        "session = HTMLSession()\n",
        "\n",
        "email=set()\n",
        "for i in tqdm(links_data_arr):\n",
        "        #requests.get(f'{i}', verify=False)\n",
        "        r = session.get(i)\n",
        "        for re_match in re.finditer(EMAIL_REGEX, r.html.raw_html.decode()):\n",
        "            email.add(((re_match.group())).replace(\"-\",\"\"))\n",
        "\n",
        "df = pd.DataFrame(email)\n",
        "df.to_csv('Emails.csv', index=False)\n"
      ],
      "metadata": {
        "id": "sxmvQ3ZyOxlw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}